---
title: "Week 11, Day 3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(PPBDS.data)
library(rstanarm)
library(tidyverse)

# Same data clean up as last week.

set.seed(1005)
week_11 <- shaming %>% 
  mutate(age = 2006 - birth_year) %>% 
  mutate(treatment = fct_relevel(treatment, "Control")) %>% 
  mutate(solo = ifelse(hh_size == 1, TRUE, FALSE)) %>% 
  select(-general_04, -no_of_names, -birth_year, -hh_size) 
```


## Scene 1

**Prompt:** Create a fitted model object called `fit_1` using this formula or, if you want, a formula which you prefer. I recommend not making your model execessively complex.

primary_06 ~ solo + primary_04 + treatment + solo:treatment

(Assume that you have already completed a cross-validation analysis and chosen this one model to use going forward.)

```{r cache = TRUE}
fit_1 <- stan_glm(primary_06 ~ solo + primary_04 + treatment + solo:treatment,
                  data = week_11, refresh = 0)
```


* Which data set should you use to fit the model? Explain why.

Full data -- we picked the model already

* Interpret the fitted model. Should we keep all these variables? And the interaction term?

We should keep everything and interaction term too! Primary_4 is a pretty  good predictor of whether you'll vote again so that seems worth keeping, everything else seems like it's significant. Solo:treatment is good for telling us whether treatments are more/less effective depending on household size. 

## Scene 2

**Prompt:** What is the causal effect of receiving the Neighbors postcard as compared to being in the control group? Provide a posterior probability distribution.

```{r}
neighbor <- tibble(treatment = c("Neighbors", "Control"), solo = FALSE,
                   primary_04 = "Yes")

pp <- posterior_predict(fit_1, newdata = neighbor) %>%
  as_tibble()

pp %>%
  mutate(diff = `1` - `2`) %>%
  mutate(diff = as.double(diff)) %>%
  ggplot(aes(x = diff, y = after_stat(count/sum(count)))) + 
    geom_histogram(bins = 50, color = "white")
```


* One way to answer this question is to use `posterior_predict()`. Do that. Make it look nice! Write a sentence or two interpreting the answer.

* A second approach uses `posterior_epred()`. Do that. Make it look nice! Write a sentence or two interpreting the answer.
```{r}
pe <- posterior_epred(fit_1, newdata = neighbor) %>%
  as_tibble()

pe %>%
  mutate(diff = `1` - `2`) %>%
  mutate(diff = as.double(diff)) %>%
  ggplot(aes(x = diff, y = after_stat(count/sum(count)))) +
    geom_histogram(color = "white", bins = 50)
```



## Scene 3

**Prompt:** There are four primary causal effects of interest: each of the four treatments compared, individually, to Control.  Build a big graphic which shows the four posterior probability distributions of the expected values at once. See #preceptors-notes for my version. You do not need to copy my work! Make something better!

* Challenge question: Do the same but for both `solo = TRUE` and `solo = FALSE`. This means that there are 8 posterior probability distributions to show. Think hard about the best way to display them. What point are you trying to get across to your readers?

```{r}

newobs <- tibble(treatment = c("Neighbors", "Self", 
                               "Hawthorne", "Civic Duty", "Control"), 
                 solo = FALSE,
                 primary_04 = "Yes")

pe_2 <- posterior_epred(fit_1, newdata = newobs) %>%
  as_tibble()

pe_2 %>%
  mutate(neighbor = `1` - `5`,
         self = `2` - `5`,
         hawthorne = `3` - `5`,
         civic_duty = `4` - `5`) %>%
  pivot_longer(cols = neighbor:civic_duty, names_to = "treatment",
               values_to = "diff") %>%
  ggplot(aes(x = diff, fill = treatment)) +
    geom_histogram(color = "white", position = "identity",
                   alpha = 0.4, bins = 100)
```

```{r}

newobs2 <- expand_grid(treatment = levels(week_11$treatment), 
                       solo = unique(week_11$solo),
                       primary_04 = c("Yes"))

pe_3 <- posterior_epred(fit_1, newdata = newobs2) %>%
  as_tibble() %>%
  mutate_all(as.numeric) %>%
  mutate(civic_false = `3` - `1`,
         civic_true = `4` - `2`,
         hawthorne_false = `5` - `1`,
         hawthorne_true = `6` - `2`,
         self_false = `7` - `1`,
         self_true = `8` - `2`,
         neighbor_false = `9` - `1`,
         neighbor_true = `10` - `2`) %>%
  select(civic_false:neighbor_true)

pe_3 %>%
  pivot_longer(cols = civic_false:neighbor_true,
               values_to = "effect",
               names_to = "treatment") %>%
  mutate(solo = ifelse(str_detect(treatment, pattern = "false"), 0, 1)) %>%
  mutate(treatment = ifelse(str_detect(treatment, pattern = "false"),
                            str_sub(treatment, end = str_length(treatment) - 6),
                            str_sub(treatment, end = str_length(treatment) - 5))) %>%
  ggplot(aes(x = effect, 
             y = after_stat(count / sum(count)), fill = treatment)) +
    geom_histogram(position = "identity", alpha = 0.5, bins = 100) +
    facet_wrap(~ solo)

```


## Optional Question

Use a logistic model --- `stan_glm()` with `family = binomial()` --- to fit the model. How does that change the results above, especially in Scene 2. Chapter 11 provides some relevant discussion?






